{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc41cbaa4063433cadc177a1febfa0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73486970caab4ec1969b0b80d627ec47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e671a12826445509249c6afc4e7b72c",
              "IPY_MODEL_19e510f566fc40d4947d5978a6eee908"
            ]
          }
        },
        "73486970caab4ec1969b0b80d627ec47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e671a12826445509249c6afc4e7b72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ddf6bbe182dc4de59c582b1786a9f323",
            "_dom_classes": [],
            "description": "epoch 0",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 125,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 53,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45ce334d6d814b2390c56f8de4f5328a"
          }
        },
        "19e510f566fc40d4947d5978a6eee908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d2c3db530c241928ca16fa18059ad2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 42% 53/125 [31:37&lt;42:52, 35.73s/it, loss=0.26973]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_082021f72725438783ac5b93c342abf0"
          }
        },
        "ddf6bbe182dc4de59c582b1786a9f323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45ce334d6d814b2390c56f8de4f5328a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d2c3db530c241928ca16fa18059ad2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "082021f72725438783ac5b93c342abf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "na6r5fjMGmD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch as tt\n",
        "import torch.utils\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "\n",
        "# Compute two different representation for each token.\n",
        "# Each representation is a linear weighted combination for the\n",
        "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
        "elmo = Elmo(options_file, weight_file, 2, dropout=0, requires_grad= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zoM3IN8yPDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from tqdm._tqdm_notebook import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVg4XKzU3SNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.set_gpu_as_default_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tib3RUFIGmuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsgroups_all = fetch_20newsgroups(subset='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GqIaQ7VGsHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups_all['data'], newsgroups_all['target'], test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3tYxpQqivYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train = len(y_train)\n",
        "n_test = len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVc5zVJgjses",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_TRAIN = 1000\n",
        "N_TEST = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kf1gBO1kylo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d11f6038-5fb3-465c-9bef-df9cc4ae9357"
      },
      "source": [
        "idx1 = np.random.choice(range(n_train), size = N_TRAIN)\n",
        "idx2 = np.random.choice(range(n_train), size = N_TRAIN)\n",
        "\n",
        "y_train_real = (np.array([y_train[i] for i in idx1]) == np.array([y_train[i] for i in idx2])).astype(int)\n",
        "y_train_real = tt.from_numpy(y_train_real).float()\n",
        "\n",
        "x_train_real1 = np.array([X_train[i][:200] for i in idx1])\n",
        "x_train_real2 = np.array([X_train[i][:200] for i in idx2])\n",
        "x_train_real1 = batch_to_ids(x_train_real1)\n",
        "x_train_real2 = batch_to_ids(x_train_real2)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI_JXOxOmJjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx1 = np.random.choice(range(n_test), size = N_TEST)\n",
        "idx2 = np.random.choice(range(n_test), size = N_TEST)\n",
        "\n",
        "y_test_real = (np.array([y_test[i] for i in idx1]) == np.array([y_test[i] for i in idx2])).astype(int)\n",
        "x_test_real1 = np.array([X_test[i][:200] for i in idx1])\n",
        "x_test_real2 = np.array([X_test[i][:200] for i in idx2])\n",
        "\n",
        "y_test_real = tt.from_numpy(y_test_real).float()\n",
        "x_test_real1 = batch_to_ids(x_test_real1)\n",
        "x_test_real2 = batch_to_ids(x_test_real2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZBS_asHbtiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 8\n",
        "train_loader = DataLoader(TensorDataset(x_train_real1, x_train_real2, y_train_real), batch_size=batch_size)\n",
        "val_loader = DataLoader(TensorDataset(x_test_real1, x_test_real2, y_test_real), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJVGooNgbtQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _train_epoch(model, iterator, optimizer, curr_epoch):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "\n",
        "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        print(all(x.requires_grad == False for x in elmo._elmo_lstm.parameters()))\n",
        "        loss = model(batch)\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        curr_loss = loss.data.cpu().detach().item()\n",
        "        \n",
        "        \n",
        "        loss_smoothing = i / (i+1)\n",
        "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
        "\n",
        "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "def _test_epoch(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    with tt.no_grad():\n",
        "        for batch in iterator:\n",
        "            loss = model(batch)\n",
        "            epoch_loss += loss.data.item()\n",
        "\n",
        "    return epoch_loss / n_batches\n",
        "\n",
        "\n",
        "def nn_train(model, train_iterator, valid_iterator, optimizer, n_epochs=100,\n",
        "          scheduler=None, early_stopping=0):\n",
        "\n",
        "    prev_loss = 100500\n",
        "    es_epochs = 0\n",
        "    best_epoch = None\n",
        "    history = pd.DataFrame()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = _train_epoch(model, train_iterator, optimizer, epoch)\n",
        "        valid_loss = _test_epoch(model, valid_iterator)\n",
        "\n",
        "        valid_loss = valid_loss\n",
        "        print('validation loss %.5f' % valid_loss)\n",
        "\n",
        "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
        "        history = history.append(record, ignore_index=True)\n",
        "\n",
        "        if early_stopping > 0:\n",
        "            if valid_loss > prev_loss:\n",
        "                es_epochs += 1\n",
        "            else:\n",
        "                es_epochs = 0\n",
        "\n",
        "            if es_epochs >= early_stopping:\n",
        "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
        "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
        "                break\n",
        "\n",
        "            prev_loss = min(prev_loss, valid_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtcx4DK_x4zS",
        "colab_type": "code",
        "outputId": "ebfcc4f1-f9ab-4b4e-a03d-578e15963f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fc41cbaa4063433cadc177a1febfa0c0",
            "73486970caab4ec1969b0b80d627ec47",
            "5e671a12826445509249c6afc4e7b72c",
            "19e510f566fc40d4947d5978a6eee908",
            "ddf6bbe182dc4de59c582b1786a9f323",
            "45ce334d6d814b2390c56f8de4f5328a",
            "4d2c3db530c241928ca16fa18059ad2a",
            "082021f72725438783ac5b93c342abf0"
          ]
        }
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, elmo, criterion):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.elmo = elmo\n",
        "        self.criterion = criterion\n",
        "        \n",
        "        #self.fc = nn.Linear(1024*2, 128)\n",
        "        self.fc = nn.Linear(1024*2, 32)\n",
        "        #self.out = nn.Linear(128*3, 1)\n",
        "        self.out = nn.Linear(32*3, 1)\n",
        "        \n",
        "    def branch(self, x):\n",
        "        x = self.elmo(x)['elmo_representations']\n",
        "        x = tt.cat(x, dim=-1)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        \n",
        "        q1, q2, y = batch\n",
        "        \n",
        "        q1 = self.branch(q1)\n",
        "        q2 = self.branch(q2)\n",
        "        \n",
        "        # simetric functions\n",
        "        x = tt.cat([tt.abs(q1-q2), q1*q2, q1+q2], dim=-1)\n",
        "        \n",
        "        x = self.out(x).squeeze(1)\n",
        "        loss = self.criterion(x,y)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "model = MyModel(elmo, nn.BCEWithLogitsLoss())\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "nn_train(model, train_loader, val_loader, optimizer, n_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc41cbaa4063433cadc177a1febfa0c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch 0', max=125, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "tensor(0.6113, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0923, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.5283, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0083, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(1.3252, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0118, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0236, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0429, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0573, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(1.1338, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.1452, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.2101, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.1601, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.3794, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0582, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4617, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0262, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0204, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0149, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.5791, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(1.1315, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.5207, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4430, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0835, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.1384, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.1555, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.3849, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.1132, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0844, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0546, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0355, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(1.4315, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0265, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0272, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4698, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0329, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0345, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.8467, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0486, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0592, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0653, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0683, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4119, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4101, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0718, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0722, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0663, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0629, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0479, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0374, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4535, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.0272, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n",
            "tensor(0.4891, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg1yPUaVIle2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(anchor_embed, pos_embed, neg_embed):\n",
        "    return F.cosine_similarity(anchor_embed, neg_embed) - F.cosine_similarity(anchor_embed, pos_embed)\n",
        "    \n",
        "    \n",
        "class Tripletnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Tripletnet, self).__init__()\n",
        "        self.elmo = elmo\n",
        "        self.fc = nn.Linear(1024*2, 128)\n",
        "        \n",
        "    def branch(self, x):\n",
        "        x = self.elmo(x)['elmo_representations']\n",
        "        x = tt.cat(x, dim=-1)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def forward(self, anchor, pos, neg):\n",
        "        \n",
        "        anchor = self.branch(anchor)\n",
        "        pos = self.branch(pos)\n",
        "        neg = self.branch(neg)\n",
        "        \n",
        "        return triplet_loss(anchor, pos, neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQG5UoH1ZQQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-nLhhYsbQD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "aedc89f7-30bc-4417-bad0-db25613221d4"
      },
      "source": [
        "model = Tripletnet()\n",
        "model.forward()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-d9d894f07a3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripletnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'anchor', 'pos', and 'neg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANGUR_b-H915",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df = df[df.index<100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HViteIDKH_qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "xq1_train = batch_to_ids(df_train.question1.values)\n",
        "xq2_train = batch_to_ids(df_train.question2.values)\n",
        "y_train = tt.from_numpy(df_train.is_duplicate.values).float()\n",
        "\n",
        "xq1_val = batch_to_ids(df_val.question1.values)\n",
        "xq2_val = batch_to_ids(df_val.question2.values)\n",
        "y_val = tt.from_numpy(df_val.is_duplicate.values).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKHjeTCOKQrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1\n",
        "train_loader = DataLoader(TensorDataset(xq1_train, xq2_train, y_train), batch_size=batch_size)\n",
        "val_loader = DataLoader(TensorDataset(xq1_val, xq2_val, y_val), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUc7MqjBLIEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "43ea7fb5-cba5-4463-b9e6-fb5f1e91426d"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>55</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>How difficult is it get into RSI?</td>\n",
              "      <td>Do you apply for programs like RSI when you're...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>88</td>\n",
              "      <td>177</td>\n",
              "      <td>178</td>\n",
              "      <td>Which is the best gaming laptop under 60k INR?</td>\n",
              "      <td>Which is the best gaming laptop under Rs 60000?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>What is web application?</td>\n",
              "      <td>What is the web application framework?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>85</td>\n",
              "      <td>86</td>\n",
              "      <td>Can I make 50,000 a month by day trading?</td>\n",
              "      <td>Can I make 30,000 a month by day trading?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>69</td>\n",
              "      <td>139</td>\n",
              "      <td>140</td>\n",
              "      <td>At what cost does so much privacy as in German...</td>\n",
              "      <td>Are there any people who genuinely enjoy salad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>122</td>\n",
              "      <td>How do I download content from a kickass torre...</td>\n",
              "      <td>Is Kickass Torrents trustworthy?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>71</td>\n",
              "      <td>143</td>\n",
              "      <td>144</td>\n",
              "      <td>What is a narcissistic personality disorder?</td>\n",
              "      <td>What is narcissistic personality disorder?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>What are some of the best romantic movies in E...</td>\n",
              "      <td>What is the best romantic movie you have ever ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>103</td>\n",
              "      <td>104</td>\n",
              "      <td>Will a Blu Ray play on a regular DVD player? I...</td>\n",
              "      <td>How can you play a Blu Ray DVD on a regular DV...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  qid1  ...                                          question2 is_duplicate\n",
              "55  55   111  ...  Do you apply for programs like RSI when you're...            0\n",
              "88  88   177  ...    Which is the best gaming laptop under Rs 60000?            1\n",
              "26  26    53  ...             What is the web application framework?            0\n",
              "42  42    85  ...          Can I make 30,000 a month by day trading?            0\n",
              "69  69   139  ...  Are there any people who genuinely enjoy salad...            0\n",
              "..  ..   ...  ...                                                ...          ...\n",
              "60  60   121  ...                   Is Kickass Torrents trustworthy?            0\n",
              "71  71   143  ...         What is narcissistic personality disorder?            1\n",
              "14  14    29  ...  What are the laws to change your status from a...            0\n",
              "92  92   185  ...  What is the best romantic movie you have ever ...            1\n",
              "51  51   103  ...  How can you play a Blu Ray DVD on a regular DV...            1\n",
              "\n",
              "[80 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJK9l8NbNfnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74f1bec9-c57f-4049-e884-bc444aa8ca9b"
      },
      "source": [
        "for i in df_train.index:\n",
        "  print(len(df_train.question1[i]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n",
            "46\n",
            "24\n",
            "41\n",
            "96\n",
            "93\n",
            "19\n",
            "56\n",
            "60\n",
            "33\n",
            "43\n",
            "135\n",
            "43\n",
            "38\n",
            "24\n",
            "86\n",
            "32\n",
            "66\n",
            "64\n",
            "28\n",
            "22\n",
            "41\n",
            "30\n",
            "26\n",
            "49\n",
            "60\n",
            "73\n",
            "79\n",
            "69\n",
            "43\n",
            "79\n",
            "50\n",
            "57\n",
            "27\n",
            "31\n",
            "42\n",
            "19\n",
            "51\n",
            "115\n",
            "66\n",
            "21\n",
            "58\n",
            "41\n",
            "67\n",
            "52\n",
            "47\n",
            "59\n",
            "43\n",
            "59\n",
            "31\n",
            "24\n",
            "49\n",
            "139\n",
            "67\n",
            "171\n",
            "41\n",
            "110\n",
            "72\n",
            "43\n",
            "39\n",
            "30\n",
            "75\n",
            "127\n",
            "38\n",
            "51\n",
            "21\n",
            "37\n",
            "73\n",
            "24\n",
            "54\n",
            "89\n",
            "69\n",
            "126\n",
            "125\n",
            "26\n",
            "70\n",
            "44\n",
            "141\n",
            "53\n",
            "56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D08P2bm7NvX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}